{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80fe442-1f0c-4a76-919d-94508075dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_file_paths = ['trainImages.zip', 'validationImages.zip']\n",
    "\n",
    "for path in zip_file_paths:\n",
    "    name = str(path)\n",
    "    with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(f'unzipped/{name.split(\".\")[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5235fd-27e3-4323-8edc-fd30d1b926f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_validation = pd.read_csv('unzipped/validationImages/labels/detections.csv')\n",
    "df_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c589dd-1711-49a8-aaa2-7a94e3a7b11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('unzipped/trainImages/labels/detections.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80749617-2c76-4be3-bc70-97a3f641b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e7c6d-2c3a-4c24-abe4-0d0e0b201821",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f487f2a1-bd3b-404e-9eab-20f85996cc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_validation = 'unzipped/validationImages/data/*.jpg'\n",
    "data_path_train = 'unzipped/trainImages/data/*.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4769b492-5a9b-48de-93bc-71a81edd1aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "counter = 0\n",
    "\n",
    "img_paths = data_path_train\n",
    "folder = glob.glob(img_paths)\n",
    "\n",
    "for i in folder:\n",
    "    counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89d1d56-60f7-419a-bf2f-9cabf5d2c7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "img_paths = data_path_validation\n",
    "folder = glob.glob(img_paths)\n",
    "\n",
    "for i in folder:\n",
    "    counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49469397-7ced-4958-b805-57e4dad4f9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "train_list_ids = []\n",
    "\n",
    "validation_list_ids = []\n",
    "\n",
    "def get_ids(split, print_this, to_append_list):\n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    if split == data_path_train:\n",
    "        start, end = 26, 42\n",
    "    elif split == data_path_validation:\n",
    "        start, end = 31, 47\n",
    "    else:\n",
    "        raise Exception(\"Invalid Parameter\")\n",
    "    folder = split\n",
    "    img_paths = glob.glob(folder)\n",
    "    img_ids = to_append_list\n",
    "    \n",
    "    for i in img_paths:\n",
    "        id = i[start:end]\n",
    "        img_ids.append(id)\n",
    "    print(len(img_ids))\n",
    "    print(print_this)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a88677-6d94-4460-9761-9f8e6be250d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ids(data_path_train, \"Task Completed!\", train_list_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac2e850-f9f1-4d31-8875-3730ffb6c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a5865a-3999-402a-947d-6c46768847dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ids(data_path_validation, \"Task Completed!\", validation_list_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d710142-389f-40ff-a395-adcd71592c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_list_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ef55d6-76b9-420f-99c5-52c9aa84ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes_df = pd.read_csv(\"unzipped/trainImages/metadata/classes.csv\", names = ['className', 'Object'])\n",
    "validation_classes_df = pd.read_csv(\"unzipped/validationImages/metadata/classes.csv\", names = ['className', 'Object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2682df-60fc-45ce-b450-eba44e98f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_identifier = train_classes_df[train_classes_df['Object'] == 'Plastic bag']\n",
    "validation_identifier = validation_classes_df[validation_classes_df['Object'] == 'Plastic bag']\n",
    "\n",
    "print(train_identifier)\n",
    "print(validation_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f957fed3-9692-46de-92c2-f11b2424713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_row_from_df(split):\n",
    "    dataframe = \"\"\n",
    "    if split == \"train\":\n",
    "        dataframe, ids_to_check = df_train, train_list_ids\n",
    "    elif split == \"validation\":\n",
    "        dataframe, ids_to_check = df_validation, validation_list_ids\n",
    "    else:\n",
    "        raise Exception(\"Invalid parameter, must be either train or validation\")\n",
    "    \n",
    "    img_ids_len = len(ids_to_check)\n",
    "    rand = random.rand_int(0,img_ids_len-1)\n",
    "    id = ids_to_check[rand]\n",
    "    print(id)\n",
    "    r = dataframe, loc[(dataframe.ImageID == id) & (dataframe.LabelName == '/m/05gqfk')]\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6e6d99-acaa-4e66-a375-3cba7b4ecc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_row_from_df(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fe62b1-3ff6-45ae-8ceb-611efdc3c6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "from PIL import image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd31259-5c5f-41fb-a28c-8be32e33db59",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_images_path = 'unzipped/validationImages/data/*.jpg'\n",
    "train_images_path = 'unzipped/trainImages/data/*.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732814f-3c6c-4780-a7c3-4f8381b278c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_random_image(split):\n",
    "    split_path = train_images_path if split split == 'train' else validation_images_path if split == 'validation' else 0\n",
    "    if split_path == 0:\n",
    "        raise Exception(\"Invalid input parameter, must be either train or validation.\")\n",
    "    images_folder = split_path\n",
    "    images_path = glob.glob(images_folder)\n",
    "    num_of_images = len(images_paths)\n",
    "    random_int = random.randint(0, num_of_images-1)\n",
    "    random_image = images_paths[random_int]\n",
    "    img = mpimg.imread(random_image)\n",
    "    \n",
    "    fig,ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f195ae-4dda-43f0-9603-53822e086c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_random_image('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e0d624-bf2b-420c-baca-eb814f5390cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18855ac-4753-4dfe-af2f-82efc016bb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "columns = 4\n",
    "rows = 5\n",
    "\n",
    "validation_images_path = 'unzipped/validationImages/data/*.jpg'\n",
    "train_images_path = 'unzipped/trainImages/data/*.jpg'\n",
    "\n",
    "def visualize_many(from_num, to_num, dataset):\n",
    "    dataset_path = train_images_path if dataset == 'train' else validation_images_path if dataset == 'validation' else 0\n",
    "    if dataset_path == 0:\n",
    "        raise Exception(\"Invalid input parameter, must be either train or validation\")\n",
    "    images_paths = glob.glob(dataset_path)\n",
    "    \n",
    "    index_counter = 1\n",
    "    for i in range(from_num, to_num):\n",
    "        counter = 1\n",
    "        image = images_paths[counter]\n",
    "        img = mpimg.imread(image)\n",
    "        fig.add_subplot(rows, columns, index_counter)\n",
    "        plt.imshow(img)\n",
    "        index_counter += 1\n",
    "    plt.show()\n",
    "\n",
    "    visualize_many(0,19,'train')\n",
    "    visualize_many(0,8,'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f95eff8-57b4-4f83-b6f9-f89c2ef9f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation.loc[(df_validation['ImageID'] == '4e222b68123ef3') & (df_validation.LabelName == '/m/05gqfk')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ae9d4c-5aa4-445c-9a3a-f9848dbe1888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "im = Image.open('unzipped/validationImages/data/4e222b68123ef3.jpg')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(im)\n",
    "\n",
    "image_width, image_height = im.size\n",
    "print(image_width, image_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd1db65-0f26-47ac-860c-92d7e8c604ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "from PIL import image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98917984-a976-4cab-a404-f1e493aea98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_images_path = 'unzipped/validationImages/data/*.jpg'\n",
    "train_images_path = 'unzipped/trainImages/data/*.jpg'\n",
    "\n",
    "def visualize_bb(dataset):\n",
    "    images_path = train_images_paths if dataset == 'train' else validation_images_path if dataset == 'validation' else 0\n",
    "    if dataset == 0:\n",
    "        raise Exception('Invalid input parameter, must be either train or validation.')\n",
    "    \n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    if dataset == 'train':\n",
    "        start, end, df, split = 26, 42, df_train, 'trainImages'\n",
    "    elif dataset == 'validation':\n",
    "        start, end, df, split = 31, 47, df_validation, 'validationImages'\n",
    "    else:\n",
    "        raise Exception('Invalid parameter')\n",
    "    \n",
    "    images_folder = images_path\n",
    "    images_paths = glob.glob(image_folder)\n",
    "    num_of_images = len(images_paths)\n",
    "    random_int = random.randint(0, num_of_images-1)\n",
    "    random_image = images_paths[random_int]\n",
    "    print(random_image)\n",
    "    img = Image.open(random_image)\n",
    "    id_of_image = random_image[start:end]\n",
    "    \n",
    "    df_rows = df.loc[(df.ImageID == id_of_image) & (df.LabelName == '/m/05gqfk')]\n",
    "    \n",
    "    image_width, image_height = img.size\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    for index, row in df_rows.iterrows():\n",
    "        print(row['XMin'],row['XMax'],row['YMin'],row['XMax'])\n",
    "    \n",
    "        xmin = row['XMin']\n",
    "        xmax = row['XMax']\n",
    "        ymin = row['YMin']\n",
    "        ymax = row['XMax']\n",
    "        \n",
    "        new_xmin = xmin * image_width\n",
    "        new_xmax = xmax * image_width\n",
    "        new_ymin = ymin * image_height\n",
    "        new_ymax = ymax * image_height\n",
    "        \n",
    "        width = new_xmax - new_xmin\n",
    "        height = new_ymax - new_ymin\n",
    "        \n",
    "        rect = patches.Rectangle((new_xmin,new_ymin), width, height, linewidth = 1, edgecolor = 'r', facecolor = 'none')\n",
    "        rect = plt.Rectangle((xmin,ymin),new_xmax - new_xmin, new_ymax - new_ymin, fill = False, edgecolor = colors[cls_id], linewidth = 3.5)\n",
    "        ax.add_patch(rect)\n",
    "    plt.show()\n",
    "\n",
    "visualize_bb('validation')\n",
    "visualize_bb('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add27b91-cb78-4c20-b5ba-e45334e82bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_train))\n",
    "print(len(df_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e0311b-3241-4132-bf45-bb8a80ea2b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df_for_train, df_for_validation):\n",
    "    df_train_cleansed = df_train[df_train['LabelName'].str.contains('/m/05gqfk')]\n",
    "    df_validation_cleansed = df_validation[df_train['LabelName'].str.contains('/m/05gqfk')]\n",
    "    \n",
    "    return df_train_cleansed, df_validation_cleansed\n",
    "\n",
    "df_train_cleansed, df_validation_cleansed = clean_dataframe(df_train, df_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f27a7e8-dad3-4b6c-b18f-362db3092cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train_cleansed)\n",
    "len(df_validation_cleansed)\n",
    "\n",
    "# We have 517 train images, but some of those images have multiple bb\n",
    "# 986 rows in df_train_cleansed\n",
    "# Each row representing one bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa1fbdb-c76e-4a05-851d-d9c85f80a0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df_train_cleansed, test = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b12d33e-bd95-4b15-bcab-e4248063d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed03b3a7-3d91-421f-9123-82d5908ea577",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ddccb5-d9d6-40d1-a4d7-9176d4beb184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "path = 'unzipped/testImages'\n",
    "os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f0a1bd-16e6-4663-aaef-daa20d7078db",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'unzipped/testImages/data'\n",
    "os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551341c3-36df-4c78-ab58-7a320946cacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = test['ImageID'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa90c485-0d6c-43b5-ba1e-860d731ea1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c330939-e37b-433d-b89c-97882f220640",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = train['ImageID'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172cf5a-9024-4bbd-8ed9-2071ca1df004",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821c4d88-b1f3-403a-ad9d-5e80637c8171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import glob\n",
    "\n",
    "to_loop = 'unzipped/trainImage/data/*.jpg'\n",
    "folder = glob.glob(to_loop)\n",
    "\n",
    "new_path = 'unzipped/testImages/data/*.jpg'\n",
    "\n",
    "for path in folder:\n",
    "    id = path[26:42]\n",
    "    if((id in test_ids) and (id in train_ids)):\n",
    "        shutil.copy(path, f'{new_path}/{id}.jpg')\n",
    "    elif((id in test_ids) and (id not in train_ids)):\n",
    "        shutil.move(path, f'{new_path}/{id}.jpg')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f98e1-0cf2-40c5-b17b-583860c2fab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_test = 'unzipped/testImages/data/*.jpg'\n",
    "\n",
    "folder = glob.glob(path_to_test)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for i in folder:\n",
    "    counter += 1\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52096d03-6efc-4701-9b0c-0dad4a700fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train = 'unzipped/trainImages/data/*.jpg'\n",
    "\n",
    "folder = glob.glob(path_to_train)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for i in folder:\n",
    "    counter += 1\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6ccb39-2d99-41ad-8102-452ad4df1722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some images are present in both, train and test folders, and thus had to be copied. \n",
    "# Total number of images thus increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87ef155-c1e9-477f-aa52-85b2958276e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_ids = []\n",
    "\n",
    "test_folder = glob.glob('unzipped/testImages/data/*.jpg')\n",
    "\n",
    "for i in test_folder:\n",
    "    id = i[25:41]\n",
    "    test_images_ids.append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6d1485-38eb-4f51-8dc7-cece14ef1e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2246a32a-bed4-4a94-8f69-63e6d468a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_ids = []\n",
    "\n",
    "train_folder = glob.glob('unzipped/trainImages/data/*.jpg')\n",
    "\n",
    "for i in train_folder:\n",
    "    id = i[26:42]\n",
    "    train_images_ids.append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4739da-c7a1-4bd2-a279-a1eb8b535ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4445cd-247c-488a-8923-ed84a0297266",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_both = set(train_df_ids).intersection(train_image_ids)\n",
    "len(train_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8619ce46-570f-4018-865d-f5769679be40",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_both = set(test_df_ids).intersection(test_image_ids)\n",
    "len(test_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f606eda-65ac-4542-84b6-c5da9f0f5e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2b5a49-a2b6-4ba8-b0ad-cd08c160791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train.copy()\n",
    "test_df = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba6f1d8-5869-4a58-9b33-1abfdeaf398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.rename(columns = {'LabelName':'className'}, inplace = True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2329eaa-bbc9-467c-873b-a63255c1bc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.rename(columns = {'LabelName':'className'}, inplace = True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bfc484-a9a6-40e3-ac94-3b1ae622eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897bcc96-187b-4f64-8d14-18ee3817bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077ca9d8-26ab-42cb-809b-ec4ac4f7d230",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['header_cols'] = 2\n",
    "train_df['label_width'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4486049a-430c-4b4b-a1f5-71f906bfecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['header_cols'] = 2\n",
    "test_df['label_width'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf7c812-7dc3-4b85-b3e1-07cb83fcbd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['ImagePath'] = '001.Plastic_bag/images/train/' + train_df['ImageID'] + '.jpg'\n",
    "test_df['ImagePath'] = '001.Plastic_bag/images/train/' + test_df['ImageID'] + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2834d3-1670-4669-b86d-9d32bd75e456",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1b5be7-2cb6-448f-b1f9-6f5a11fb70bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ffac49-24e4-4932-bdde-bc26a63413dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[['header_cols', 'label_width', 'className', 'XMin', 'YMin', 'XMax', 'YMax', 'ImagePath']]\n",
    "test_df = test_df[['header_cols', 'label_width', 'className', 'XMin', 'YMin', 'XMax', 'YMax', 'ImagePath']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f254a54a-1029-4e21-b358-495b08bce76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.precision', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866cdfa7-65a5-47ec-ba62-8d2f5dca655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_df = train_df.copy()\n",
    "final_train_df['className'] = '0.000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311fc08a-ed7a-450c-8dfa-9e1307658363",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955e2acc-1cb3-4dce-8c9a-1e4c0f12e16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_df = test_df.copy()\n",
    "final_test_df['className'] = '0.000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4955536-ea5d-47cb-a276-d99d7ec2739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f14f805-55b8-4427-b029-91f4d80c4227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.move('unzipped/trainImages/data', '001.Plastic_bag/images/train')\n",
    "shutil.move('unzipped/testImages/data', '001.Plastic_bag/images/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f1b9ed-a5c5-466d-b0c2-44a6f22a76fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "folder = glob.glob('001.Plastic_bag/images/test/*.jpg')\n",
    "count = 0\n",
    "for i in folder:\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b818353d-6d00-439a-ba43-c85b73c37b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "folder = glob.glob('001.Plastic_bag/images/train/*.jpg')\n",
    "count = 0\n",
    "for i in folder:\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684dd943-be0c-4306-ade9-bbcfc771dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NEW FOLDER STRUCTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c88ed3f-8770-48df-8178-9f2285560461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.move('001.Plastic_bag/images/test', 'PlasticDetection/images/001.Plastic_bag/images/test')\n",
    "shutil.move('001.Plastic_bag/images/train', 'PlasticDetection/images/001.Plastic_bag/images/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7938dec9-acbc-4a0e-9cbb-f88e5900e9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611fe265-4db5-457f-b2d5-d92b971583c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLIP\n",
    "\n",
    "# new_x = w/2 - (x - w/2)\n",
    "# new_y = y\n",
    "# im = im.transpose(Image.Transpose.FLIP_LEFT_RIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfd2dbf-7bf3-4981-9da6-b59455feda0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import random\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "test_images_path = 'PlasticDetection/images/001.Plastic_bag/images/test/*.jpg'\n",
    "train_images_path = 'PlasticDetection/images/001.Plastic_bag/images/train/*.jpg'\n",
    "\n",
    "def visualize_transpose(dataset):\n",
    "    images_path = train_images_paths if dataset == 'train' else validation_images_path if dataset == 'validation' else 0\n",
    "    if dataset == 0:\n",
    "        raise Exception('Invalid input parameter, must be either train or validation.')\n",
    "    \n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    if dataset == 'train':\n",
    "        start, end, df, split = 53, 69, final_train_df, 'train'\n",
    "    elif dataset == 'test':\n",
    "        start, end, df, split = 52, 68, final_test_df, 'test'\n",
    "    else:\n",
    "        raise Exception('Invalid parameter')\n",
    "    \n",
    "    images_folder = images_path\n",
    "    images_paths = glob.glob(image_folder)\n",
    "    num_of_images = len(images_paths)\n",
    "    random_int = random.randint(0, num_of_images-1)\n",
    "    random_image = images_paths[random_int]\n",
    "    #print(random_image)\n",
    "    img = Image.open(random_image)\n",
    "    img = img.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "    id_of_image = random_image[start:end]\n",
    "    \n",
    "    # df_rows = df.loc[(df.ImageID == id_of_image) & (df.LabelName == '/m/05gqfk')]\n",
    "    df_rows = df.loc[(df.ImagePath == f'001.Plastic_bag/images/{split}/{id_of_image}.jpg') & (df.className == '0.000')]\n",
    "    \n",
    "    image_width, image_height = img.size\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    for index, row in df_rows.iterrows():\n",
    "        print(row['XMin'],row['XMax'],row['YMin'],row['XMax'])\n",
    "    \n",
    "        xmin = row['XMin']\n",
    "        xmax = row['XMax']\n",
    "        ymin = row['YMin']\n",
    "        ymax = row['XMax']\n",
    "        \n",
    "        new_xmin = xmin * image_width\n",
    "        new_xmax = xmax * image_width\n",
    "        new_ymin = ymin * image_height\n",
    "        new_ymax = ymax * image_height\n",
    "        \n",
    "        # FLipping the bounding box coordinates\n",
    "        xmax_flipped = (image_width/2) - (new_xmin-(image_width/2)) # technically the xmax now\n",
    "        xmin_flipped = (image_width/2) - (new_xmax-(image_width/2)) # technically the xmin now\n",
    "        \n",
    "        width = xmax_flipped - xmin_flipped\n",
    "        height = new_ymax - new_ymin\n",
    "        \n",
    "        rect = patches.Rectangle((xmin_flipped,new_ymin), width, height, linewidth = 1, edgecolor = 'r', facecolor = 'none')\n",
    "        #rect = plt.Rectangle((xmin,ymin),new_xmax - new_xmin, new_ymax - new_ymin, fill = False, edgecolor = colors[cls_id], linewidth = 3.5)\n",
    "        rect = patches.Rectangle((xmin_flipped,new_ymin),  xmax_flipped - xmin_flipped, new_ymax - new_ymin, linewidth = 1, edgecolor = 'r', facecolor = 'none')\n",
    "        ax.add_patch(rect)\n",
    "    plt.show()\n",
    "\n",
    "visualize_transpose('test')\n",
    "visualize_transpose('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0380ce26-ca33-417e-b879-ae8064da01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_path = 'PlasticDetection/images/001.Plastic_bag/images/test/*.jpg'\n",
    "train_images_path = 'PlasticDetection/images/001.Plastic_bag/images/train/*.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2aafaa-08b9-409d-8ae2-572bf1b675d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(dataset):\n",
    "    images_path = train_images_path if dataset == 'train' else test_images_path if dataset == 'test' else 0\n",
    "    if images_path == 0:\n",
    "        raise Exception('Invalid input parameter')\n",
    "    start = 0\n",
    "    end = 0\n",
    "    if dataset == 'train':\n",
    "        start, end, df = 29, 45, final_train_df\n",
    "    elif dataset == 'test':\n",
    "        start, end, df= 28, 44, final_test_df\n",
    "    \n",
    "    temp_df = pd.DataFrame(columns=['header_cols','label_width', 'className','XMin','YMin', 'XMax', 'YMax','ImagePath'], dtype=object)\n",
    "    \n",
    "    counter=0\n",
    "    for index, row in d.iterrows():\n",
    "        img_path = row['ImagePath'] # image path in the df\n",
    "        id = img_path[start:end]\n",
    "        im_path = f'PlasticDetection/images/001.Plastic_bag/images/{dataset}/{id}.jpg' #image path for the physical location\n",
    "        img = Image.open(im_path)\n",
    "        image_width, image_height = img.size\n",
    "        img_flip = img.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "        img_flip.save(f'PlasticDetection/images/001.Plastic_bag/images/{dataset}/flipped_{id}.jpg')\n",
    "        \n",
    "        xmin = row['XMin'] * image_width\n",
    "        xmax = row['XMax'] * image_width\n",
    "        ymin = row['YMin']\n",
    "        ymax = row['XMax']\n",
    "        \n",
    "        # getting the new coordinates for the flipped bounding boxes\n",
    "        new_xmin = ((image_width/2)-(xmin-(image_width/2))) / image_width\n",
    "        new_xmax = ((image_width/2)-(xmax-(image_width/2))) / image_width\n",
    "        \n",
    "        temp_df.loc[counter]=[2.5,\"0.000\",new_xmin,ymin,new_xmax,ymax,new_image_path]\n",
    "        counter += 1\n",
    "    df_merged = df.append(temp_df, ignore_index = True)\n",
    "    df_merged.to_csv(f'{dataset}.lst', sep='\\t', float_format = '%.4f', header=None)\n",
    "    print(len(df))\n",
    "    print(len(temp_df))\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8d5a41-9eda-41d2-8702-3a672e3a31bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = glob.glob(train_images_path)\n",
    "counter = 0\n",
    "for i in folder:\n",
    "    counter = 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c5f9f6-e415-4d12-8b24-03954a4050a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d026f680-fb91-4105-ac7f-f56c9c302959",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24cca4f-e77f-4ed8-8997-5b57533dc79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a97d12-2f5e-4a60-b3f1-0bd0bf8b43b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_data('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf99cb77-e082-44c3-a1ba-838b5913a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEVOPS - SETTING UP THE TRAINING JOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2054c937-bf24-4ec5-bd20-eca636456f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "if platform.linux_distribution()[0] == \"debian\":\n",
    "    ! apt-get update\n",
    "    ! apt-get install ffmpeg libsm6 libxext6 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69246365-29d4-42ab-8658-dd9b05a36c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "!{sys.executable} -m pip install opencv-python\n",
    "!{sys.executable} -m pip install mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e812e04e-623f-4eaf-ab03-900b0a70563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESIZE_SIZE = 256\n",
    "BASE_DIR = \"PlasticDetection/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653f61bc-09c7-4da5-ad9b-72b35bec8796",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python tools/im2rec.py --resize $RESIZE_SIZE --pack-label test $BASE_DIR/images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686cb3d6-347a-4b58-840d-fd541741934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python tools/im2rec.py --resize $RESIZE_SIZE --pack-label train $BASE_DIR/images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc95e0bc-4fd0-42e6-8594-6354404d6f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "bucket = \"plastic-object-detection-2023\"\n",
    "prefix = \"DEMO-ObjectDetection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6b94ff-7e65-4657-89f1-95b902156835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c690aa-f055-476f-bc9d-18fba75678ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channel = prefix + \"/train\"\n",
    "sess.upload_data(path=\"train.rec\", bucket = bucket, key_prefix = train_channel)\n",
    "s3_train_data = \"s3://{}//{}\".format(bucket, train_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1596b3e5-1016-441c-b98a-c3ff3c1d1a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s3_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08276022-100e-45e9-a94e-8dbc12602092",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_channel = prefix + \"/validation\"\n",
    "sess.upload_data(path=\"test.rec\", bucket = bucket, key_prefix = validation_channel)\n",
    "s3_validation_data = \"s3://{}//{}\".format(bucket, validation_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f502e5f-11cf-4803-9a95-57b1da6b6a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s3_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74cf515-2cc8-4c45-b577-eb0b0d87d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = \"s3://{}//{}/output\".format(bucket, prefix)\n",
    "print(s3_output_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6231f838-5cdc-4175-8fa6-151e99e38e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "training_image = image_uris.retrieve(\n",
    "    region = sess.boto_region_name, framework = \"object-detection\", version = \"1\"\n",
    ")\n",
    "\n",
    "print(training_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdfd9c9-c820-4d00-985f-6f58e8a7108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "od_model = sagemaker.estimator.Estimator(\n",
    "    training_image,\n",
    "    role,\n",
    "    instance_count = 1,\n",
    "    instance_type = \"ml.p3.2xlarge\",\n",
    "    volume_size = 50,\n",
    "    max_run = 360000,\n",
    "    input_mode = 'File',\n",
    "    output_path = s3_output_location,\n",
    "    sagemaker_session = sess\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd8dd5c-c9a8-463e-ae7f-ed9633b2d32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(od_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17779d1-5291-4f47-b4b7-ffae4dc4deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e176b5-4853-4119-8cc5-931215631bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "folder = glob.glob('PlasticDetection/images/001.Plastic_bag/images/train/*jpg')\n",
    "tr_sample_counter = 0\n",
    "for i in folder:\n",
    "    tr_sample_counter += 1\n",
    "print(tr_sample_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f3204f-3598-4c3f-84f4-e4521fc33d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_hyperparameters(num_epochs, lr_steps):\n",
    "    num_classes = 1\n",
    "    num_training_samples = tr_sample_counter\n",
    "    \n",
    "    od_model.set_hyperparameters(\n",
    "        base_network = \"resnet-50\",\n",
    "        use_pretrained_model = 1, # Use the pretrained weights of resnet-50, enable transfer learning\n",
    "        num_classes = num_classes,\n",
    "        epochs = num_epochs,\n",
    "        lr_scheduler_step = lr_steps, # At these epochs, LR will be decreased\n",
    "        lr_scheduler_factor = 0.1,\n",
    "        momentum = 0.9, # Extension to the gradient descent algorithm (optimizer algorithm)\n",
    "        # Builds inertia in the direction of the global minima\n",
    "        # Helps to overcome oscillations and noise\n",
    "        weight_decay = 0.0005, # Weight Decay Coeffcient for SGD and RMSPROP, Prevents overfitting\n",
    "        # We're not letting the algorithm rely on any one weight too much that it has learned\n",
    "        nms_threshold = 0.45, # Non-Max suppression threshold - removes redundant predicitons with low confidences. \n",
    "        # If any object gets detected by the model but has a confidence score of less than 45%, it will be ignored.\n",
    "        image_shape = 512,\n",
    "        num_training_samples = tr_sample_counter\n",
    "    )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db9fd7f-e7b7-4922-b382-c6296ac61971",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_hyperparameters(100, '20,30,40,50,55') # '50,70,80,90,95'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c39eae7-4b4f-4b0b-8cd4-ebe2eeab26c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/object-detection-api-config.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1f5656-dfec-424b-b6f6-fc154ad00330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\"\"\"\n",
    "Hyperparameter Tuning:\n",
    "In this, we are not just training a single model, we are training many models.\n",
    "The reason we want to do that is because we want to experience different kind of parameters.\n",
    "Let's say we want to try out the learning rate to be 0.1 in one case and then 0.8 the other case.\n",
    "Insteam of doing this manually, we can set up hyper parameter tuning so that it does the training or the hyper \n",
    "parameter tuning automatically for us. So we just set up the parameters, then SageMaker is going to tune our \n",
    "algorithm as many times as we define it. In the following code segment, we are just setting up different kinds \n",
    "of values that we want to plug into our model and see how they perform with that value.\n",
    "\n",
    "We keep in mind that Sagemaker uses the Bayesian search for hyper parameter tuning. There's also grid search, \n",
    "but Bayesian search is the most popular, which is why it's the default value for AWS as well.\n",
    "The reason for that is because Bayesian search learns from previous hyper parameter tuning jobs. \n",
    "\n",
    "Let's suppose we had three hyper parameter tuning jobs so far and we've set a max to be five. Then let's say we \n",
    "have we're at three right now and the Bayesian search sees that whenever we use stochastic gradient descent, in \n",
    "the past two times the algorithm performed really well. But when we used another optimizer like the Rmsprop, it \n",
    "performed really poorly. So it's not going to choose Rmsprop for the next hyper parameter tuning job. It's going \n",
    "to choose the optimizer that has worked best so far. Optimizer is going to be one of the hyper parameters that we tune.\n",
    "\"\"\"\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"learning_rate\": ContinuousParameter(0.001,0.1), # Any value between 0.001 and 0.1 is acceptable \n",
    "    \"mini_batch_size\": CategoricalParameter([8,16]), # These three values are acceptable # [8,16,32,64]\n",
    "    \"optimizer\": CategoricalParameter([\"sgd\",\"adam\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ac2b37-ecd7-4687-a45d-39109acfc04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_jobs = 4 # 8\n",
    "max_parallel_jobs = 1\n",
    "objective_metric_name = \"validation:mAP\" # Mean Average Precision\n",
    "objective_type = \"Maximize\" # We are trying to maximize mean average precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2521b9ad-147a-4e3f-9024-683200aafdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(estimator = od_model,\n",
    "                           objective_metric_name = objective_metric_name,\n",
    "                           hyperparameter_ranges = hyperparameter_ranges,\n",
    "                           objective_type = objective_type,\n",
    "                           max_jobs = max_jobs,\n",
    "                           max_parallel_jobs = max_parallel_jobs\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1f1d11-2915-4b77-9650-a40d0ac49b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://jonathan-hui.medium.com/map-mean-average-precision-for-object-detection-45c121a31173"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0a9835-55d8-4b78-8f6a-55b468820e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.inputs.TrainingInput( \n",
    "    # S3DataDistributionType - https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_S3DataSource.html\n",
    "    s3_train_data,\n",
    "    distribution = \"FullyReplicated\",\n",
    "    content_type = \"application/x-recordio\",\n",
    "    s3_data_type = \"S3Prefix\"\n",
    ")\n",
    "\n",
    "validation_data = sagemaker.inputs.TrainingInput( \n",
    "    s3_validation_data,\n",
    "    distribution = \"FullyReplicated\",\n",
    "    content_type = \"application/x-recordio\",\n",
    "    s3_data_type = \"S3Prefix\"\n",
    ")\n",
    "\n",
    "data_channels = {\"train\": train_data, \"validation\": validation_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20da2b8a-36dd-4bca-acf6-a90c22eecebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit(input = data_channels, logs = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f180c5c6-06df-4fee-805a-bbc43d1dc7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Go to sagemaker -> your region -> hyper-tuningjobs\n",
    "Check if your current job is running\n",
    "\n",
    "Use CloudWatch -> Metrics to monitor the training job\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "https://www.researchgate.net/figure/mAP-Comparison-results-on-each-network-in-COCO-dataset_tbl6_348825339\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64075f54-7231-4d6a-8f38-3d24e3c008e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77189f42-913a-484e-96fe-77d876336e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "from sagemaker import image_uris\n",
    "\n",
    "training_image = image_uris.retrieve(\n",
    "    region = sess.boto_region_name, framework = \"object-detection\", version = \"1\"\n",
    ")\n",
    "\n",
    "print(training_image)\n",
    "# we are calling it an image becuse essentially its a docker image (it lives in ECR - Elastic Container Registry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3a9fdc-f1bf-47d2-a939-242ad60c9cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sagemaker.model.Model(\n",
    "    image_uri = training_image,\n",
    "    model_data = '', # s3 model uri\n",
    "    role = role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516cfc2b-5f72-44be-9071-d30fed3fbea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = 'Plastic-detection-endpoint-001'\n",
    "\n",
    "deployment = model.deploy(\n",
    "    initial_instance_count = 1,\n",
    "    instance_type = \"ml.m4.xlarge\",\n",
    "    endpoint_name = endpoint_name\n",
    ")\n",
    "\n",
    "# sagemaker -> inference -> endpoints\n",
    "\n",
    "\"\"\"\n",
    "IMPORTANT: DELETE YOUR ENDPOINT AFTER USE - TO PREVENT AWS CHARGES\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f143deed-00f0-4b51-827c-2b6fbf68b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "runtime = boto3.client(service_name = \"runtime.sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1639a7c5-4e14-4d21-a9a5-be8179dfef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as mpimg\n",
    "\n",
    "def visualize_detection(img_file, dets, thresh = 0.6):\n",
    "    img = mpimg.imread(img_file)\n",
    "    plt.imshow(img)\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    colors = dict()\n",
    "    num_detections = 0\n",
    "    for det in dets:\n",
    "        (klass, score, x0, y0, x1, y1) = det\n",
    "        if score < thresh:\n",
    "            continue\n",
    "        num_detections += 1\n",
    "        cls_id = int(klass)\n",
    "        if(cls_id not in colors):\n",
    "            colors[cls_id] = (random.random(), random.random(), random.random())\n",
    "        xmin = int(x0*width)\n",
    "        ymin = int(y0*height)\n",
    "        xmax = int(x1*width)\n",
    "        ymax = int(y1*height)\n",
    "        rect = plt.Rectangle(\n",
    "            (xmin, ymin),\n",
    "            xmax-xmin,\n",
    "            ymax- ymin,\n",
    "            fill = False,\n",
    "            edgecolor = colors[cls_id],\n",
    "            linewidth = 3.5\n",
    "        )\n",
    "        plt.gca().add_patch(rect)\n",
    "        plt.gca().text(\n",
    "            xmin,\n",
    "            ymin,\n",
    "            \"{:.3f}\".format(score),\n",
    "            bbox = dict(facecolor = colors[cls_id, alpha = 0.5]),\n",
    "            fontsize = 12,\n",
    "            color = \"white\"\n",
    "        )\n",
    "    print(\"Number of detections:\" + str(num_detections))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b16a4a-c532-40ca-9ba3-e4b6371d92e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plastic_prediction():\n",
    "    b = \"\"\n",
    "    with open(filename, \"rb\") as image:\n",
    "        f = image.read()\n",
    "        b = bytearray(f)\n",
    "    endpoint_response = runtime.invoke_endpoint(EndpointName = ep, ContentType = \"images/jpeg\", Body = b)\n",
    "    results = endpoint_response[\"Body\"].read()\n",
    "    detections = json.loads(results)\n",
    "    \n",
    "    visualize_detection(filename, detections[\"prediction\"], thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65540dce-c23c-4ec2-afde-dfa2feb60682",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plastic_prediction('unzipped/validationImages/data/...', endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd63007-0fdb-4f3e-990b-96fd82754450",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TESTING ENDPOINT ON RANDOM PICTURES FROM THE INTERNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1b6be-278d-4e89-932d-b43cf44709d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plastic_prediction('InternetImages/...', endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa57557-46f7-4a38-811b-cc8b4647f88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "IMPORTANT: DELETE YOUR ENDPOINT AFTER USE - TO PREVENT AWS CHARGES\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e44ec48-3578-41c4-8ffc-56bdd75e6cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SETTING UP BATCH TRANSFORMATION JOB - LOCALLY FIRST"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-south-1:394103062818:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
